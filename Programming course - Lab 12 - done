{"cells":[{"cell_type":"markdown","metadata":{"id":"6tBf-6qhgh1T"},"source":["# Lab 12 - Pivoting and unpivoting\n","\n","This lab focuses on data transformation using pivoting and unpivoting operations with the polars library."]},{"cell_type":"markdown","metadata":{"id":"1YGGOBvigh1V"},"source":["## Load your packages\n","\n","You will need the `polars` package for this assignment. We'll also use `numpy` for some calculations."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"W9Fz8gWUgh1V","executionInfo":{"status":"ok","timestamp":1755375171288,"user_tz":240,"elapsed":653,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}}},"outputs":[],"source":["# Import required packages\n","import polars as pl"]},{"cell_type":"markdown","metadata":{"id":"grS7pHHdgh1W"},"source":["# Question 1: Pivot US Economic Indicator Data"]},{"cell_type":"markdown","metadata":{"id":"fi_R0t6Wgh1X"},"source":["## 1a. Pivot data\n","\n","Load the `economics_long.csv` dataset from the `data/` folder. You'll notice that in the `economics_long` dataset's `value` column, there are different types of measurements. Transform this dataset so that the unique values for the `variable` field become columns of their own.\n","\n","**Please write code below to pivot the data. The output should be a DataFrame. You must \"pivot\" the data to receive full credit on this question.**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"VN8x_y2ugh1X","executionInfo":{"status":"ok","timestamp":1755375176598,"user_tz":240,"elapsed":486,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}},"outputId":"44c0b440-7c6d-46bd-e62a-ebd32e30a4aa"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3793025439.py:5: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n","  economics_wide = economics_long.pivot(\n"]},{"output_type":"execute_result","data":{"text/plain":["shape: (574, 6)\n","┌────────────┬─────────┬────────────┬─────────┬─────────┬──────────┐\n","│ date       ┆ pce     ┆ pop        ┆ psavert ┆ uempmed ┆ unemploy │\n","│ ---        ┆ ---     ┆ ---        ┆ ---     ┆ ---     ┆ ---      │\n","│ str        ┆ f64     ┆ f64        ┆ f64     ┆ f64     ┆ f64      │\n","╞════════════╪═════════╪════════════╪═════════╪═════════╪══════════╡\n","│ 1967-07-01 ┆ 506.7   ┆ 198712.0   ┆ 12.6    ┆ 4.5     ┆ 2944.0   │\n","│ 1967-08-01 ┆ 509.8   ┆ 198911.0   ┆ 12.6    ┆ 4.7     ┆ 2945.0   │\n","│ 1967-09-01 ┆ 515.6   ┆ 199113.0   ┆ 11.9    ┆ 4.6     ┆ 2958.0   │\n","│ 1967-10-01 ┆ 512.2   ┆ 199311.0   ┆ 12.9    ┆ 4.9     ┆ 3143.0   │\n","│ 1967-11-01 ┆ 517.4   ┆ 199498.0   ┆ 12.8    ┆ 4.7     ┆ 3066.0   │\n","│ …          ┆ …       ┆ …          ┆ …       ┆ …       ┆ …        │\n","│ 2014-12-01 ┆ 12062.0 ┆ 319746.157 ┆ 7.6     ┆ 12.9    ┆ 8717.0   │\n","│ 2015-01-01 ┆ 12046.0 ┆ 319928.646 ┆ 7.7     ┆ 13.2    ┆ 8903.0   │\n","│ 2015-02-01 ┆ 12082.4 ┆ 320074.511 ┆ 7.9     ┆ 12.9    ┆ 8610.0   │\n","│ 2015-03-01 ┆ 12158.3 ┆ 320230.786 ┆ 7.4     ┆ 12.0    ┆ 8504.0   │\n","│ 2015-04-01 ┆ 12193.8 ┆ 320402.295 ┆ 7.6     ┆ 11.5    ┆ 8526.0   │\n","└────────────┴─────────┴────────────┴─────────┴─────────┴──────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (574, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>pce</th><th>pop</th><th>psavert</th><th>uempmed</th><th>unemploy</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;1967-07-01&quot;</td><td>506.7</td><td>198712.0</td><td>12.6</td><td>4.5</td><td>2944.0</td></tr><tr><td>&quot;1967-08-01&quot;</td><td>509.8</td><td>198911.0</td><td>12.6</td><td>4.7</td><td>2945.0</td></tr><tr><td>&quot;1967-09-01&quot;</td><td>515.6</td><td>199113.0</td><td>11.9</td><td>4.6</td><td>2958.0</td></tr><tr><td>&quot;1967-10-01&quot;</td><td>512.2</td><td>199311.0</td><td>12.9</td><td>4.9</td><td>3143.0</td></tr><tr><td>&quot;1967-11-01&quot;</td><td>517.4</td><td>199498.0</td><td>12.8</td><td>4.7</td><td>3066.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2014-12-01&quot;</td><td>12062.0</td><td>319746.157</td><td>7.6</td><td>12.9</td><td>8717.0</td></tr><tr><td>&quot;2015-01-01&quot;</td><td>12046.0</td><td>319928.646</td><td>7.7</td><td>13.2</td><td>8903.0</td></tr><tr><td>&quot;2015-02-01&quot;</td><td>12082.4</td><td>320074.511</td><td>7.9</td><td>12.9</td><td>8610.0</td></tr><tr><td>&quot;2015-03-01&quot;</td><td>12158.3</td><td>320230.786</td><td>7.4</td><td>12.0</td><td>8504.0</td></tr><tr><td>&quot;2015-04-01&quot;</td><td>12193.8</td><td>320402.295</td><td>7.6</td><td>11.5</td><td>8526.0</td></tr></tbody></table></div>"]},"metadata":{},"execution_count":3}],"source":["# Load economics_long data\n","economics_long = pl.read_csv(\"https://raw.githubusercontent.com/philhetzel/opan5510-class12/main/data/economics_long.csv\")\n","\n","# Pivot the data\n","economics_wide = economics_long.pivot(\n","    values=\"value\",\n","    index=\"date\",\n","    columns=\"variable\"\n",")\n","\n","# Display the pivoted dataframe\n","economics_wide\n"]},{"cell_type":"markdown","metadata":{"id":"evuuI_Uwgh1Y"},"source":["## 1b. Calculate median unemployment for 2010-01-01 and beyond\n","\n","Next, compute the median unemployment metric (as defined by `unemploy`) for 2010-01-01 and beyond.\n","\n","**Please write code below. The output should show the median value. You must use the dataframe created in 1a.**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"597QVPcEgh1Y","executionInfo":{"status":"ok","timestamp":1755375234481,"user_tz":240,"elapsed":69,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}},"outputId":"306efb32-dfdb-4d2a-accd-c8af923b4513"},"outputs":[{"output_type":"stream","name":"stdout","text":["The median unemployment for 2010-01-01 and beyond is: 12471.0\n"]}],"source":["median_unemploy = (\n","    economics_wide\n","    .with_columns(pl.col(\"date\").str.to_date().alias(\"date\"))\n","    .filter(pl.col(\"date\") >= pl.date(2010, 1, 1))\n","    .select(pl.col(\"unemploy\").median().alias(\"median_unemploy\"))\n","    .to_series()\n","    .item()\n",")\n","\n","print(f\"The median unemployment for 2010-01-01 and beyond is: {median_unemploy}\")\n"]},{"cell_type":"markdown","metadata":{"id":"8oInpuCxgh1Z"},"source":["### Answer: The median unemployment for 2010-01-01 and beyond is: __________"]},{"cell_type":"markdown","source":["12471"],"metadata":{"id":"VHQ3ZSHIhK3a"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Yo8ATiCFhKLr"}},{"cell_type":"markdown","metadata":{"id":"5l2cOrpfgh1Z"},"source":["# Question 2: Air Passenger data"]},{"cell_type":"markdown","metadata":{"id":"_8MtwThVgh1Z"},"source":["## 2a. Unpivot data\n","\n","The `AirPassengers` dataset is wide, which makes it difficult to aggregate. Transform the `AirPassengers` dataset from wide to long. The resulting dataset should have three columns: one column representing year, one column representing month, and one column representing the number of air passengers.\n","\n","**Please write code below to unpivot the data. The output should be a DataFrame. You must \"unpivot\" the data to receive full credit on this question.**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"DMR8EWsPgh1Z","executionInfo":{"status":"ok","timestamp":1755375327753,"user_tz":240,"elapsed":142,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}},"outputId":"f8e845f2-eeab-4f53-ae6d-b08fa16e8b9d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["shape: (144, 3)\n","┌──────┬───────┬────────────┐\n","│ Year ┆ Month ┆ Passengers │\n","│ ---  ┆ ---   ┆ ---        │\n","│ i64  ┆ str   ┆ i64        │\n","╞══════╪═══════╪════════════╡\n","│ 1949 ┆ Jan   ┆ 112        │\n","│ 1950 ┆ Jan   ┆ 115        │\n","│ 1951 ┆ Jan   ┆ 145        │\n","│ 1952 ┆ Jan   ┆ 171        │\n","│ 1953 ┆ Jan   ┆ 196        │\n","│ …    ┆ …     ┆ …          │\n","│ 1956 ┆ Dec   ┆ 306        │\n","│ 1957 ┆ Dec   ┆ 336        │\n","│ 1958 ┆ Dec   ┆ 337        │\n","│ 1959 ┆ Dec   ┆ 405        │\n","│ 1960 ┆ Dec   ┆ 432        │\n","└──────┴───────┴────────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (144, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Year</th><th>Month</th><th>Passengers</th></tr><tr><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>1949</td><td>&quot;Jan&quot;</td><td>112</td></tr><tr><td>1950</td><td>&quot;Jan&quot;</td><td>115</td></tr><tr><td>1951</td><td>&quot;Jan&quot;</td><td>145</td></tr><tr><td>1952</td><td>&quot;Jan&quot;</td><td>171</td></tr><tr><td>1953</td><td>&quot;Jan&quot;</td><td>196</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1956</td><td>&quot;Dec&quot;</td><td>306</td></tr><tr><td>1957</td><td>&quot;Dec&quot;</td><td>336</td></tr><tr><td>1958</td><td>&quot;Dec&quot;</td><td>337</td></tr><tr><td>1959</td><td>&quot;Dec&quot;</td><td>405</td></tr><tr><td>1960</td><td>&quot;Dec&quot;</td><td>432</td></tr></tbody></table></div>"]},"metadata":{},"execution_count":5}],"source":["# Load AirPassengers data\n","air_passengers = pl.read_csv(\n","    \"https://raw.githubusercontent.com/philhetzel/opan5510-class12/main/data/AirPassengers.txt\",\n","    separator=\"\\t\"\n",")\n","\n","# Unpivot months into a single column\n","air_passengers_long = air_passengers.unpivot(\n","    index=[\"Year\"],\n","    on=air_passengers.columns[1:],   # all month columns\n","    variable_name=\"Month\",\n","    value_name=\"Passengers\"\n",")\n","\n","# Display the unpivoted dataframe\n","air_passengers_long\n"]},{"cell_type":"markdown","metadata":{"id":"pAQg7v55gh1a"},"source":["## 2b. Find the standard deviation between 1955 and 1960\n","\n","Next, compute the standard deviation of passengers between (and including) the years 1955 and 1960.\n","\n","**Please write code below. The output should show the standard deviation. You must use the dataframe created in 2a.**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GruMSkzrgh1a","executionInfo":{"status":"ok","timestamp":1755375359680,"user_tz":240,"elapsed":37,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}},"outputId":"812c9470-da1c-4799-a164-41f23f70a58d"},"outputs":[{"output_type":"stream","name":"stdout","text":["The standard deviation of airline passengers between 1955 and 1960 is: 86.44\n"]}],"source":["std_passengers = (\n","    air_passengers_long\n","    .filter((pl.col(\"Year\") >= 1955) & (pl.col(\"Year\") <= 1960))\n","    .select(pl.col(\"Passengers\").std().alias(\"std_passengers\"))\n","    .to_series()\n","    .item()\n",")\n","\n","print(f\"The standard deviation of airline passengers between 1955 and 1960 is: {std_passengers:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"wrGZrV60gh1a"},"source":["### The standard deviation of airline passengers between (and including) the years 1955 and 1960 is: __________"]},{"cell_type":"markdown","source":["86.44"],"metadata":{"id":"6ivW--0xhm6v"}},{"cell_type":"markdown","metadata":{"id":"MY_460N9gh1a"},"source":["# Question 3: WHO tuberculosis case data"]},{"cell_type":"markdown","metadata":{"id":"oNqmcSJJgh1a"},"source":["## 3a. Pivot data\n","\n","Load the `table2.csv` dataset from the `data/` folder. This contains data for country populations and tuberculosis case metrics. You'll notice that the metrics for `cases` and `population` are in the same column (`count`). Pivot the data so that the metrics for `cases` and `population` are in their own columns.\n","\n","**Please write code below to pivot the data. The output should be a DataFrame. You must \"pivot\" the data to receive full credit on this question.**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"PHS2JgkWgh1a","executionInfo":{"status":"ok","timestamp":1755375414004,"user_tz":240,"elapsed":115,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}},"outputId":"dc38dc8f-5088-4a61-8ffb-ae20386eac6c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1973591259.py:5: DeprecationWarning: The argument `columns` for `DataFrame.pivot` is deprecated. It has been renamed to `on`.\n","  table2_wide = table2.pivot(\n"]},{"output_type":"execute_result","data":{"text/plain":["shape: (6, 4)\n","┌─────────────┬──────┬────────┬────────────┐\n","│ country     ┆ year ┆ cases  ┆ population │\n","│ ---         ┆ ---  ┆ ---    ┆ ---        │\n","│ str         ┆ i64  ┆ i64    ┆ i64        │\n","╞═════════════╪══════╪════════╪════════════╡\n","│ Afghanistan ┆ 1999 ┆ 745    ┆ 19987071   │\n","│ Afghanistan ┆ 2000 ┆ 2666   ┆ 20595360   │\n","│ Brazil      ┆ 1999 ┆ 37737  ┆ 172006362  │\n","│ Brazil      ┆ 2000 ┆ 80488  ┆ 174504898  │\n","│ China       ┆ 1999 ┆ 212258 ┆ 1272915272 │\n","│ China       ┆ 2000 ┆ 213766 ┆ 1280428583 │\n","└─────────────┴──────┴────────┴────────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (6, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>cases</th><th>population</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1999</td><td>745</td><td>19987071</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>2000</td><td>2666</td><td>20595360</td></tr><tr><td>&quot;Brazil&quot;</td><td>1999</td><td>37737</td><td>172006362</td></tr><tr><td>&quot;Brazil&quot;</td><td>2000</td><td>80488</td><td>174504898</td></tr><tr><td>&quot;China&quot;</td><td>1999</td><td>212258</td><td>1272915272</td></tr><tr><td>&quot;China&quot;</td><td>2000</td><td>213766</td><td>1280428583</td></tr></tbody></table></div>"]},"metadata":{},"execution_count":7}],"source":["# Load table2 data\n","table2 = pl.read_csv(\"https://raw.githubusercontent.com/philhetzel/opan5510-class12/main/data/table2.csv\")\n","\n","# Pivot data so 'cases' and 'population' become their own columns\n","table2_wide = table2.pivot(\n","    values=\"count\",\n","    index=[\"country\", \"year\"],\n","    columns=\"type\"\n",")\n","\n","# Display the pivoted dataframe\n","table2_wide\n"]},{"cell_type":"markdown","metadata":{"id":"JAN_mQtTgh1a"},"source":["## 3b. Calculate highest cases/population ratio for 1999\n","\n","Now that you have `cases` and `population` in their own columns, you can perform analysis. Create a new column in this dataset called `ratio` that divides `cases` by `population`. Next, filter the data to only include rows from the `year` of 1999. What is the country with the highest `cases`/`population` ratio?\n","\n","**Please write code below. You must use the dataframe created in 3a.**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k56NDZeBgh1b","executionInfo":{"status":"ok","timestamp":1755375589446,"user_tz":240,"elapsed":17,"user":{"displayName":"Karl Witte","userId":"12683021148178478893"}},"outputId":"0dd03d57-d8d7-4d10-d8b9-8a4e50e8a90d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data for 1999 with ratios:\n","shape: (3, 5)\n","┌─────────────┬──────┬────────┬────────────┬──────────┐\n","│ country     ┆ year ┆ cases  ┆ population ┆ ratio    │\n","│ ---         ┆ ---  ┆ ---    ┆ ---        ┆ ---      │\n","│ str         ┆ i64  ┆ i64    ┆ i64        ┆ f64      │\n","╞═════════════╪══════╪════════╪════════════╪══════════╡\n","│ Afghanistan ┆ 1999 ┆ 745    ┆ 19987071   ┆ 0.000037 │\n","│ Brazil      ┆ 1999 ┆ 37737  ┆ 172006362  ┆ 0.000219 │\n","│ China       ┆ 1999 ┆ 212258 ┆ 1272915272 ┆ 0.000167 │\n","└─────────────┴──────┴────────┴────────────┴──────────┘\n","\n","The country with the highest cases/population ratio in 1999 is: Brazil\n"]}],"source":["# 1. Add ratio column\n","table2_with_ratio = table2_wide.with_columns(\n","    (pl.col(\"cases\") / pl.col(\"population\")).alias(\"ratio\")\n",")\n","\n","# 2. Filter for year 1999\n","year_1999 = table2_with_ratio.filter(pl.col(\"year\") == 1999)\n","\n","# 3. Find country with highest ratio\n","highest_ratio_country = (\n","    year_1999.sort(\"ratio\", descending=True)\n","    .head(1) # Select only the top row\n","    .select(\"country\")\n","    .to_series()\n","    .item() # Now .item() will work as it's a single value Series\n",")\n","\n","print(\"Data for 1999 with ratios:\")\n","print(year_1999)\n","print(f\"\\nThe country with the highest cases/population ratio in 1999 is: {highest_ratio_country}\")"]},{"cell_type":"markdown","metadata":{"id":"ysmmNmOAgh1b"},"source":["### Answer: The country with the highest cases/population ratio in 1999 is: __________"]},{"cell_type":"markdown","source":["Brazil"],"metadata":{"id":"i-uwMqzYiMzs"}},{"cell_type":"markdown","metadata":{"id":"hB2Qa0zkgh1b"},"source":["## Submission Instructions\n","\n","1. Complete all code cells above\n","2. Run all cells to ensure they execute without errors\n","3. Fill in the answer blanks with your computed values\n","4. Save and submit your completed notebook"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}